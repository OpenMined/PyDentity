{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modern-buddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPython autoawait is `on`, and set to use `asyncio`\n"
     ]
    }
   ],
   "source": [
    "%autoawait\n",
    "import time\n",
    "import asyncio\n",
    "from aries_basic_controller.aries_controller import AriesAgentController\n",
    "    \n",
    "WEBHOOK_HOST = \"0.0.0.0\"\n",
    "WEBHOOK_PORT = 8042\n",
    "WEBHOOK_BASE = \"\"\n",
    "ADMIN_URL = \"http://researcher-agent:8041\"\n",
    "\n",
    "\n",
    "# Based on the aca-py agent you wish to control\n",
    "agent_controller = AriesAgentController(webhook_host=WEBHOOK_HOST, webhook_port=WEBHOOK_PORT,\n",
    "                                       webhook_base=WEBHOOK_BASE, admin_url=ADMIN_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mechanical-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.create_task(agent_controller.listen_webhooks())\n",
    "\n",
    "def messages_handler(payload):\n",
    "    connection_id = payload[\"connection_id\"]\n",
    "    asyncio.get_event_loop().create_task(agent_controller.messaging.send_message(connection_id, \"This is a response from Bob\"))\n",
    "    print(\"Handle message\", payload, connection_id)\n",
    "\n",
    "\n",
    "message_listener = {\n",
    "    \"handler\": messages_handler,\n",
    "    \"topic\": \"basicmessages\"\n",
    "}\n",
    "\n",
    "\n",
    "def connection_handler(payload):\n",
    "    print(\"Connection Handler Called\")\n",
    "    connection_id = payload[\"connection_id\"]\n",
    "    state = payload[\"state\"]\n",
    "    print(f\"Connection {connection_id} in State {state}\")\n",
    "    \n",
    "connection_listener = {\n",
    "    \"handler\": connection_handler,\n",
    "    \"topic\": \"connections\"\n",
    "}\n",
    "\n",
    "agent_controller.register_listeners([connection_listener, message_listener], defaults=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "widespread-biology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Handler Called\n",
      "Connection 10bf00c7-fe28-4f15-ac2c-f598e3e60257 in State invitation\n",
      "Connection ID 10bf00c7-fe28-4f15-ac2c-f598e3e60257\n",
      "Invitation\n",
      "{'@type': 'did:sov:BzCbsNYhMrjHiqZDTUASHg;spec/connections/1.0/invitation', '@id': '31d22c96-b531-467a-8637-867f0e9199ac', 'label': 'Health Researcher', 'serviceEndpoint': 'http://172.17.0.1:8040', 'recipientKeys': ['Hu8va1kwBxycxKa731q6FeenAmhk5s3x2X3MXXR7CckE']}\n",
      "Connection Handler Called\n",
      "Connection 10bf00c7-fe28-4f15-ac2c-f598e3e60257 in State request\n"
     ]
    }
   ],
   "source": [
    "# Create Invitation\n",
    "invite = await agent_controller.connections.create_invitation()\n",
    "connection_id = invite[\"connection_id\"]\n",
    "invite_message = invite['invitation']\n",
    "print(\"Connection ID\", connection_id)\n",
    "print(\"Invitation\")\n",
    "print(invite_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-treaty",
   "metadata": {},
   "source": [
    "## Copy the invitation output from 4 and to the hospital notebook you are connecting to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "possible-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection Handler Called\n",
      "Connection 10bf00c7-fe28-4f15-ac2c-f598e3e60257 in State response\n",
      "ACCEPT REQUEST\n",
      "{'created_at': '2021-01-23 14:21:34.771903Z', 'routing_state': 'none', 'accept': 'manual', 'invitation_key': 'Hu8va1kwBxycxKa731q6FeenAmhk5s3x2X3MXXR7CckE', 'initiator': 'self', 'my_did': '8wvYweJAFRYr4LZA77hYqa', 'invitation_mode': 'once', 'updated_at': '2021-01-23 14:22:26.279182Z', 'connection_id': '10bf00c7-fe28-4f15-ac2c-f598e3e60257', 'their_label': 'Royal Infirmary of Edinburgh', 'state': 'response', 'their_did': 'ALrPXCqEuqa5wYFUDDkfeo'}\n",
      "state response\n"
     ]
    }
   ],
   "source": [
    "# Accept Request for Invite created\n",
    "connection = await agent_controller.connections.accept_request(connection_id)\n",
    "print(\"ACCEPT REQUEST\")\n",
    "print(connection)\n",
    "print(\"state\", connection[\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collected-employee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trust Ping {'thread_id': 'fed59ad7-f56e-4724-832d-00a9234dfa6b'}\n",
      "Connection Handler Called\n",
      "Connection 10bf00c7-fe28-4f15-ac2c-f598e3e60257 in State active\n"
     ]
    }
   ],
   "source": [
    "trust_ping = await agent_controller.messaging.trust_ping(connection_id, \"hello\")\n",
    "print(\"Trust Ping\", trust_ping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-enclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "trust_ping = await agent_controller.messaging.trust_ping(connection_id, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "measured-drill",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COORDINATOR IS CLEANING THE VALIDATION SET\n",
      "COORDINATOR DATA                Timestamp  Age  Gender         Country state self_employed  \\\n",
      "0    2014-08-29 09:29:37   25    Male   United States    PA            No   \n",
      "1    2014-08-29 09:31:37   42    male   United States    IN            No   \n",
      "2    2014-08-29 09:31:49   34    male   United States    PA            No   \n",
      "3    2014-08-29 09:33:43   26  female   United States    OH            No   \n",
      "4    2014-08-29 09:35:46   35    Male  United Kingdom   NaN            No   \n",
      "..                   ...  ...     ...             ...   ...           ...   \n",
      "254  2015-09-12 11:17:21   26    male  United Kingdom   NaN            No   \n",
      "255  2015-09-26 01:07:35   32    Male   United States    IL            No   \n",
      "256  2015-11-07 12:36:58   34    male   United States    CA            No   \n",
      "257  2015-11-30 21:25:06   46       f   United States    NC            No   \n",
      "258  2016-02-01 23:04:31   25    Male   United States    IL            No   \n",
      "\n",
      "    family_history treatment work_interfere    no_employees  ...  \\\n",
      "0              Yes       Yes          Often            6-25  ...   \n",
      "1              Yes       Yes      Sometimes            6-25  ...   \n",
      "2              Yes       Yes          Often         100-500  ...   \n",
      "3               No       Yes      Sometimes          26-100  ...   \n",
      "4              Yes       Yes      Sometimes             1-5  ...   \n",
      "..             ...       ...            ...             ...  ...   \n",
      "254             No       Yes            NaN          26-100  ...   \n",
      "255            Yes       Yes          Often          26-100  ...   \n",
      "256            Yes       Yes      Sometimes  More than 1000  ...   \n",
      "257             No        No            NaN         100-500  ...   \n",
      "258            Yes       Yes      Sometimes          26-100  ...   \n",
      "\n",
      "                  leave mental_health_consequence phys_health_consequence  \\\n",
      "0         Somewhat easy                        No                      No   \n",
      "1            Don't know                     Maybe                      No   \n",
      "2             Very easy                        No                      No   \n",
      "3            Don't know                     Maybe                      No   \n",
      "4             Very easy                       Yes                     Yes   \n",
      "..                  ...                       ...                     ...   \n",
      "254       Somewhat easy                        No                      No   \n",
      "255  Somewhat difficult                        No                      No   \n",
      "256  Somewhat difficult                       Yes                     Yes   \n",
      "257          Don't know                       Yes                      No   \n",
      "258          Don't know                     Maybe                      No   \n",
      "\n",
      "        coworkers    supervisor mental_health_interview phys_health_interview  \\\n",
      "0             Yes           Yes                   Maybe                 Maybe   \n",
      "1    Some of them           Yes                      No                 Maybe   \n",
      "2             Yes           Yes                   Maybe                 Maybe   \n",
      "3    Some of them            No                   Maybe                 Maybe   \n",
      "4    Some of them  Some of them                      No                 Maybe   \n",
      "..            ...           ...                     ...                   ...   \n",
      "254  Some of them  Some of them                      No                    No   \n",
      "255  Some of them           Yes                      No                    No   \n",
      "256            No            No                      No                    No   \n",
      "257            No            No                      No                    No   \n",
      "258  Some of them            No                      No                    No   \n",
      "\n",
      "    mental_vs_physical obs_consequence comments  \n",
      "0           Don't know              No      NaN  \n",
      "1           Don't know              No      NaN  \n",
      "2           Don't know              No      NaN  \n",
      "3           Don't know             Yes      NaN  \n",
      "4                  Yes             Yes      NaN  \n",
      "..                 ...             ...      ...  \n",
      "254         Don't know              No      NaN  \n",
      "255                Yes              No      NaN  \n",
      "256                 No              No      NaN  \n",
      "257                 No              No      NaN  \n",
      "258         Don't know              No      NaN  \n",
      "\n",
      "[259 rows x 27 columns]\n",
      "VALIDATION SET HAS BEEN CLEANED\n"
     ]
    }
   ],
   "source": [
    "# Data pre-processing\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# prep\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import binarize, LabelEncoder, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "print(\"COORDINATOR IS CLEANING THE VALIDATION SET\")\n",
    "\n",
    "#Read in Data\n",
    "train_df = pd.read_csv('coordinator_validation_data.csv')\n",
    "\n",
    "print(\"COORDINATOR DATA\", train_df)\n",
    "\n",
    "########## START DATA CLEANING ###############\n",
    "#Let’s get rid of the variables \"Timestamp\",“comments”, “state” just to make our lives easier.\n",
    "train_df = train_df.drop(['comments'], axis= 1)\n",
    "train_df = train_df.drop(['state'], axis= 1)\n",
    "train_df = train_df.drop(['Timestamp'], axis= 1)\n",
    "\n",
    "# Assign default values for each data type\n",
    "defaultInt = 0\n",
    "defaultString = 'NaN'\n",
    "defaultFloat = 0.0\n",
    "\n",
    "# Create lists by data tpe\n",
    "intFeatures = ['Age']\n",
    "stringFeatures = ['Gender', 'Country', 'self_employed', 'family_history', 'treatment', 'work_interfere',\n",
    "                 'no_employees', 'remote_work', 'tech_company', 'anonymity', 'leave', 'mental_health_consequence',\n",
    "                 'phys_health_consequence', 'coworkers', 'supervisor', 'mental_health_interview', 'phys_health_interview',\n",
    "                 'mental_vs_physical', 'obs_consequence', 'benefits', 'care_options', 'wellness_program',\n",
    "                 'seek_help']\n",
    "floatFeatures = []\n",
    "\n",
    "# Clean the NaN's\n",
    "for feature in train_df:\n",
    "    if feature in intFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultInt)\n",
    "    elif feature in stringFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultString)\n",
    "    elif feature in floatFeatures:\n",
    "        train_df[feature] = train_df[feature].fillna(defaultFloat)\n",
    "    else:\n",
    "        print('Error: Feature %s not recognized.' % feature)\n",
    "\n",
    "#clean 'Gender'\n",
    "#Slower case all columm's elements\n",
    "gender = train_df['Gender'].str.lower()\n",
    "#print(gender)\n",
    "\n",
    "#Select unique elements\n",
    "gender = train_df['Gender'].unique()\n",
    "\n",
    "#Made gender groups\n",
    "male_str = [\"male\", \"m\", \"male-ish\", \"maile\", \"mal\", \"male (cis)\", \"make\", \"male \", \"man\",\"msle\", \"mail\", \"malr\",\"cis man\", \"Cis Male\", \"cis male\"]\n",
    "trans_str = [\"trans-female\", \"something kinda male?\", \"queer/she/they\", \"non-binary\",\"nah\", \"all\", \"enby\", \"fluid\", \"genderqueer\", \"androgyne\", \"agender\", \"male leaning androgynous\", \"guy (-ish) ^_^\", \"trans woman\", \"neuter\", \"female (trans)\", \"queer\", \"ostensibly male, unsure what that really means\"]\n",
    "female_str = [\"cis female\", \"f\", \"female\", \"woman\",  \"femake\", \"female \",\"cis-female/femme\", \"female (cis)\", \"femail\"]\n",
    "\n",
    "for (row, col) in train_df.iterrows():\n",
    "\n",
    "    if str.lower(col.Gender) in male_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='male', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in female_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='female', inplace=True)\n",
    "\n",
    "    if str.lower(col.Gender) in trans_str:\n",
    "        train_df['Gender'].replace(to_replace=col.Gender, value='trans', inplace=True)\n",
    "\n",
    "#Get rid of bullshit\n",
    "stk_list = ['A little about you', 'p']\n",
    "train_df = train_df[~train_df['Gender'].isin(stk_list)]\n",
    "\n",
    "#complete missing age with mean\n",
    "train_df['Age'].fillna(train_df['Age'].median(), inplace = True)\n",
    "\n",
    "# Fill with media() values < 18 and > 120\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s<18] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "s = pd.Series(train_df['Age'])\n",
    "s[s>120] = train_df['Age'].median()\n",
    "train_df['Age'] = s\n",
    "\n",
    "#Ranges of Age\n",
    "train_df['age_range'] = pd.cut(train_df['Age'], [0,20,30,65,100], labels=[\"0-20\", \"21-30\", \"31-65\", \"66-100\"], include_lowest=True)\n",
    "\n",
    "#There are only 0.20% of self work_interfere so let's change NaN to \"Don't know\n",
    "#Replace \"NaN\" string from defaultString\n",
    "\n",
    "train_df['work_interfere'] = train_df['work_interfere'].replace([defaultString], 'Don\\'t know' )\n",
    "\n",
    "#Encoding data\n",
    "labelDict = {}\n",
    "for feature in train_df:\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_df[feature])\n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    train_df[feature] = le.transform(train_df[feature])\n",
    "    # Get labels\n",
    "    labelKey = 'label_' + feature\n",
    "    labelValue = [*le_name_mapping]\n",
    "    labelDict[labelKey] =labelValue\n",
    "\n",
    "#Get rid of 'Country'\n",
    "train_df = train_df.drop(['Country'], axis= 1)\n",
    "\n",
    "# Scaling Age\n",
    "scaler = MinMaxScaler()\n",
    "train_df['Age'] = scaler.fit_transform(train_df[['Age']])\n",
    "\n",
    "# define X and y\n",
    "feature_cols = ['Age', 'Gender', 'family_history', 'benefits', 'care_options', 'anonymity', 'leave', 'work_interfere']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df.treatment\n",
    "\n",
    "# split X and y into training and testing sets\n",
    "X_test, y_test = X, y\n",
    "\n",
    "# Transform pandas dataframe to torch tensor for DL\n",
    "\n",
    "x_test_data = torch.from_numpy(X_test.values)\n",
    "x_test_data = x_test_data.float()\n",
    "\n",
    "y_test_data = []\n",
    "for data in y_test.values:\n",
    "    y_test_data.append([data])\n",
    "y_test_data = torch.tensor(y_test_data).float()\n",
    "\n",
    "print(\"VALIDATION SET HAS BEEN CLEANED\")\n",
    "\n",
    "########## END DATA CLEANING ###############\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "elementary-bouquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# models\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "# The Researcher generates the model\n",
    "\n",
    "model = nn.Sequential(\n",
    "            nn.Linear(8, 4),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(2, 1),\n",
    "            nn.Sigmoid()\n",
    ")\n",
    "\n",
    "torch.save(model, \"../model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-company",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.pt to Base64 text and Send it to the hospital\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "positive-procedure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOSPITAL MODEL LOADED\n",
      "\n",
      "PRINTING PARAMETERS:\n",
      "\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=4, bias=True)\n",
      "  (1): Sigmoid()\n",
      "  (2): Linear(in_features=4, out_features=2, bias=True)\n",
      "  (3): Sigmoid()\n",
      "  (4): Linear(in_features=2, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "\n",
      "\n",
      "0.weight tensor([[ 1.5149,  1.4357, -0.7174,  0.3806,  0.3705,  1.1451, -1.0300, -4.0701],\n",
      "        [-2.1123,  1.6906, -1.8210, -0.3734, -0.5095, -1.0946, -1.4837,  1.5619],\n",
      "        [-0.2669,  0.9192, -2.6004, -0.3604, -0.9123, -0.4561,  1.5589, -0.5680],\n",
      "        [-0.5884,  0.8660,  0.6667, -1.6752,  0.4187,  0.8137,  1.2785, -2.8669]])\n",
      "0.bias tensor([2.0214, 1.1634, 0.6690, 0.6215])\n",
      "2.weight tensor([[ 4.0814,  2.8046,  1.8664,  2.8660],\n",
      "        [-2.4376, -1.6406, -0.7205, -2.2948]])\n",
      "2.bias tensor([-2.9719,  1.7671])\n",
      "4.weight tensor([[-6.6559,  4.7370]])\n",
      "4.bias tensor([2.0326])\n",
      "\n",
      "\n",
      "\n",
      "HOSPITAL IS VALIDATING\n",
      "Model loss on validation set:  tensor(-5.6757, grad_fn=<SumBackward0>)\n",
      "Confusion Matrix:\n",
      "                Actual_True, Actual_False \n",
      " Predicted_True     115    |      37     \n",
      " Predicted_False    29      |       77     \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Receive the Trained model.pt from the hospital and validate it\n",
    "\n",
    "# Pull in model\n",
    "\n",
    "model_dir = os.getcwd() + \"/../trained_model.pt\"\n",
    "\n",
    "model = torch.load(model_dir)\n",
    "\n",
    "print(\"HOSPITAL MODEL LOADED\")\n",
    "print(\"\\nPRINTING PARAMETERS:\\n\\n\")\n",
    "\n",
    "\n",
    "print(model)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "\n",
    "# Validation Logic\n",
    "print(\"\\n\\n\\nHOSPITAL IS VALIDATING\")\n",
    "\n",
    "#BINARIZE PREDICTION FOR CONFUSION MATRIX\n",
    "\n",
    "pred = []\n",
    "\n",
    "for data in  model(x_test_data):\n",
    "    if data > .5:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)\n",
    "\n",
    "\n",
    "confusion = metrics.confusion_matrix(pred, y_test_data)\n",
    "\n",
    "print(\"Model loss on validation set: \", (model(x_test_data) - y_test_data).sum())\n",
    "print(\"Confusion Matrix:\\n                Actual_True, Actual_False \\n Predicted_True    \",confusion[1][1],\"   |     \",confusion[1][0],\"    \\n Predicted_False   \",confusion[0][1],\"     |      \",confusion[0][0],\"    \\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-testing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the model to the next Hospital\n",
    "# Receive the Trained Model and Validate again\n",
    "# Repeat until all Hospitals Trained the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-necessity",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = await agent_controller.terminate()\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
